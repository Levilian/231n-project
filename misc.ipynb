{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"misc.ipynb","provenance":[],"authorship_tag":"ABX9TyPCntK8iOLunZ9GHzEyeQTa"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"nmYap7uE520R","colab_type":"code","colab":{}},"source":["# optionally download dataset locally onto VM\n","\n","# taken from https://github.com/nsadawi/Download-Large-File-From-Google-Drive-Using-Python/blob/master/Download-Large-File-from-Google-Drive.ipynb\n","import requests\n","\n","def download_file_from_google_drive(id, destination):\n","    URL = \"https://drive.google.com/uc?export=download\"\n","\n","    session = requests.Session()\n","\n","    response = session.get(URL, params = { 'id' : id }, stream = True)\n","    token = None\n","    for key, value in response.cookies.items():\n","        if key.startswith('download_warning'):\n","            token = value\n","\n","    if token:\n","        params = { 'id' : id, 'confirm' : token }\n","        response = session.get(URL, params = params, stream = True)\n","\n","    CHUNK_SIZE = 32768\n","\n","    with open(destination, \"wb\") as f:\n","        for chunk in tqdm(response.iter_content(CHUNK_SIZE)):\n","            if chunk: # filter out keep-alive new chunks\n","                f.write(chunk)\n","\n","file_id = '0B7ISyeE8QtDdTjE1MG9Gcy1kSkE'\n","destination = os.path.join(dir_data, 'sketchy_rendered.7z')\n","download_file_from_google_drive(file_id, destination)\n","\n","!7za x {destination}"],"execution_count":0,"outputs":[]}]}